{"componentChunkName":"component---src-templates-markdown-remark-js","path":"/data-science/ai4ci/docs/workshop/model_development.md","result":{"data":{"site":{"siteMetadata":{"title":"Operate First"}},"markdownRemark":{"id":"16a2de78-8abd-576c-827c-5f63d0fb24d3","html":"<h1 id=\"model-development\" style=\"position:relative;\"><a href=\"#model-development\" aria-label=\"model development permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Model Development</h1>\n<p>In this section, we will learn how to train an AIOps model from scratch. The model that we plan to train in particular is a Time to Merge prediction model which offers time estimates on when a Pull Request on a Git repository will be merged. To train such a model we look at historic pull request data of the repository (can also be extended to organization) and engineer features from the Pull Requests which can impact the time to merge of a Pull Request.</p>\n<p>To train such a model, we will be using a Jupyterlab environment and make use of jupyter notebooks. The following steps will walk you through how to train a Github time to merge model.</p>\n<h2 id=\"set-environment-variables\" style=\"position:relative;\"><a href=\"#set-environment-variables\" aria-label=\"set environment variables permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Set Environment Variables</h2>\n<p>This is an important step to get right for successfully being able to run the jupyter notebooks.</p>\n<ul class=\"pf-c-list\">\n<li>Go to <a href=\"https://jupyterhub-aiops-tools-workshop.apps.smaug.na.operate-first.cloud/hub/spawn\">Jupyterhub</a> and select the <code class=\"language-text\">Openshift CI Analysis Notebook Image</code> and the “Workshop” container size.</li>\n</ul>\n<p>If you do not have access to the Jupyterlab instance being used for this workshop, move to chapter on <a href=\"./onboarding.md\">Onboarding</a>.</p>\n<ul class=\"pf-c-list\">\n<li>Open the terminal and clone your forked Github repository in Jupyterhub.</li>\n</ul>\n<p>First set up your github configuration in Jupyterhub</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">git config --global user.email &quot;you@example.com&quot;\ngit config --global user.name &quot;Your Name&quot;</code></pre></div>\n<p>Optional: You can also <a href=\"https://docs.github.com/en/authentication/managing-commit-signature-verification\">generate an SSH key</a> and add it to your github account at <a href=\"https://github.com/settings/keys\">https://github.com/settings/keys</a>.</p>\n<p><code class=\"language-text\">git clone https://github.com/{YOUR-USERNAME}/ocp-ci-analysis</code></p>\n<p>If you do not have a Github account or have not forked the repository, move to chapter on <a href=\"./git_setup.md\">Set up Git environment</a>.</p>\n<ul class=\"pf-c-list\">\n<li>Set up environment variables at the root of the repository.</li>\n</ul>\n<p>Once you have cloned the repository, <a href=\"https://linuxize.com/post/linux-cd-command/\">cd</a> into the repository and create a <code class=\"language-text\">.env</code> file.</p>\n<p><code class=\"language-text\">cd ocp-ci-analysis</code></p>\n<p><code class=\"language-text\">vi .env</code></p>\n<p><a href=\"https://www.cs.colostate.edu/helpdocs/vi.html\">Add</a> the following contents to the .env file. For env file refer to this <a href=\"https://vault.bitwarden.com/#/send/zTA4PuNJwEW6kq7ZAUnY8g/pf51QZhZcEQ4QCEN7Lbszw\">link</a>. The password to this vault will be shared during the workshop. Copy the contents of the file from bitwarden and paste it in your <code class=\"language-text\">.env</code> file.</p>\n<p>For an example <code class=\"language-text\">.env</code> file refer to this <a href=\"../../notebooks/time-to-merge-prediction/workshop/env_example_workshop\">sample env file</a>.</p>\n<p><a href=\"https://www.cs.colostate.edu/helpdocs/vi.html\">Save</a> the file and start going over the notebooks.</p>\n<p><strong>Note</strong>: We would be downloading Pull Requests data from a Github repository.</p>\n<p>For faster download, choose a repository which does not have too many PRs. For example purposes, we have chosen a repository with ~1000 PRs</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">    GITHUB_REPO= Github repository that you wish to download\n    GITHUB_ORG= Github organization that the repository belongs to. If it&#39;s on your personal account, this will be your username.\n    S3_ACCESS_KEY= S3 bucket access key\n    S3_ENDPOINT_URL= S3 bucket endpoint\n    S3_BUCKET= S3 bucket name\n    S3_SECRET_KEY= S3 bucket secret key\n    CEPH_BUCKET= S3 bucket name\n    CEPH_BUCKET_PREFIX= set this to your username, this is the location/key where the files will be stored on S3 storage\n    CEPH_KEY_ID= S3 bucket access key ID\n    CEPH_SECRET_KEY= S3 bucket secret key\n    GITHUB_ACCESS_TOKEN= Your Github personal access token generated from the previous step\n    TRINO_USER= trino user\n    TRINO_PASSWD= trino password\n    TRINO_HOST= trino host\n    TRINO_PORT= trino port\n    CHOSEN_MODEL= Model that you wish to choose for deployment. Either one of &#39;rf&#39;, &#39;xgbc&#39;, &#39;svc&#39;, &#39;gnb&#39;\n    REMOTE=1</code></pre></div>\n<h2 id=\"model-development-1\" style=\"position:relative;\"><a href=\"#model-development-1\" aria-label=\"model development 1 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Model Development</h2>\n<p>In this workshop, we will be training a machine learning model using tools and services available on Operate First.</p>\n<p>To directly see the model development running in a pipeline or in action, skip to the <a href=\"./ml_pipeline.md\">next section</a></p>\n<p>This section comprises of 3 notebooks:</p>\n<ul class=\"pf-c-list\">\n<li><a href=\"../../notebooks/time-to-merge-prediction/workshop/01_data_collection.ipynb\">01<em>data</em>collection</a></li>\n<li><a href=\"../../notebooks/time-to-merge-prediction/workshop/02_feature_engineering.ipynb\">02<em>feature</em>engineering</a></li>\n<li><a href=\"../../notebooks/time-to-merge-prediction/workshop/03_model_training.ipynb\">03<em>model</em>training</a></li>\n</ul>\n<p>The aim of the model that we are training is to take a Github repository of interest and predict the time that it will take to merge a new Pull Request. For that purpose, we frame the “time taken to merge a PR” as a classification problem where we predict whether the time taken to merge a PR falls within one of a few predefined time ranges.</p>\n<h3 id=\"data-collection\" style=\"position:relative;\"><a href=\"#data-collection\" aria-label=\"data collection permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Data collection</h3>\n<p>In order to collect the data from Github repositories, we use the thoth-station <a href=\"https://github.com/thoth-station/mi-scheduler\">MI- Scheduler</a> that collects and analyzes metadata information from Github repositories and stores them on ceph object storage. We use the MI-Scheduler tool to collect Pull Request data from a repository of your choice.</p>\n<h3 id=\"feature-engineering\" style=\"position:relative;\"><a href=\"#feature-engineering\" aria-label=\"feature engineering permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Feature engineering</h3>\n<p>After collecting the data, we perform some initial exploration such as correlation analysis on the dataset to discover any interesting insights. We then engineer features which are needed to train a classification model which predicts the time to merge of a PR.</p>\n<p>We transform the input columns obtained from pull requests such as size of a PR, types of files added in a PR, description of a PR into various features which can be ingested by an ML Model.</p>\n<h3 id=\"model-training\" style=\"position:relative;\"><a href=\"#model-training\" aria-label=\"model training permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Model training</h3>\n<p>After performing initial data analysis and feature engineering, we train a machine learning model to classify the time<em>to</em>merge values for PRs into one of 10 bins (or “classes”). To train this model, we use the features engineered from the raw PR data. We explored various vanilla classifiers, like Naive Bayes, SVM, Random Forests, and XGBoost and save the best performing model on S3 storage.</p>","fields":{"srcLink":"https://github.com/aicoe-aiops/ocp-ci-analysis/blob/master/docs/workshop/model_development.md"},"frontmatter":{"title":"","description":null,"extraClasses":null,"banner":null}}},"pageContext":{"id":"16a2de78-8abd-576c-827c-5f63d0fb24d3"}},"staticQueryHashes":["1764348645","2823140819","3000541721","3606484676"]}