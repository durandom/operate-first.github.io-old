{"componentChunkName":"component---src-templates-markdown-remark-js","path":"/data-science/ds-workflows/docs/develop_collaborate/track-metrics-using-kubeflow.md","result":{"data":{"site":{"siteMetadata":{"title":"Operate First"}},"markdownRemark":{"id":"102932e4-7a86-5c1a-be9c-6c0815745fcd","html":"<h1 id=\"experiment-tracking-using-kubeflow-pipelines\" style=\"position:relative;\"><a href=\"#experiment-tracking-using-kubeflow-pipelines\" aria-label=\"experiment tracking using kubeflow pipelines permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Experiment tracking using Kubeflow Pipelines</h1>\n<p><a href=\"https://youtu.be/mZ98f9TWDCk\"><img src=\"https://img.youtube.com/vi/mZ98f9TWDCk/0.jpg\" alt=\"Experiment Tracking\"></a></p>\n<p>In this guide you will learn how to use kubeflow pipelines to track metrics from different experiments and runs.</p>\n<p><a href=\"https://www.kubeflow.org/docs/components/pipelines/\">Kubeflow Pipelines</a> is a platform for building and deploying scalable machine learning (ML) workflows. It allows us to automate the running of  jupyter notebooks and scripts using a simple workflow. Using Kubeflow pipelines we can automate the running of multiple steps of a ML pipeline like data collection, model training, inference, and control which steps need to be performed sequentially and which should run in  parallel.</p>\n<p>Kubeflow pipelines also allow us to <a href=\"https://www.kubeflow.org/docs/components/pipelines/sdk/pipelines-metrics/\">export metrics</a> from a running pipeline. This helps us compare multiple runs over multiple model training runs. We can also compare the achieved model performance metrics like accuracy, f1, etc.</p>\n<h2 id=\"pre-requisites\" style=\"position:relative;\"><a href=\"#pre-requisites\" aria-label=\"pre requisites permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Pre-requisites</h2>\n<ol class=\"pf-c-list\">\n<li>Existing kubeflow pipeline instance available and the components (notebooks or scripts) that you want to track metrics for.</li>\n</ol>\n<p><em>For a guide on how to create an pipeline using Elyra, Kubeflow pipelines check out this <a href=\"https://youtu.be/iMSOal8wRj4\">video</a></em></p>\n<h2 id=\"track-metrics\" style=\"position:relative;\"><a href=\"#track-metrics\" aria-label=\"track metrics permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Track Metrics</h2>\n<p>To enable tracking of metrics during the execution of a machine learning experiment, your component must have an output called <code class=\"language-text\">mlpipeline-metrics</code>  which must return a JSON-serialized metrics dictionary. Let’s demonstrate this with the help of an example.</p>\n<p>Below we will demonstrate how to capture metrics for the time taken to execute certain queries, and the time taken to upload some files to S3 storage.</p>\n<ol class=\"pf-c-list\">\n<li>Declare a file where you want to store the captured metrics. It must be named <code class=\"language-text\">mlpipeline-metrics.json</code>.</li>\n</ol>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\"># file to store runtime kfpipeline metrics\nmetrics_file_path = &#39;./mlpipeline-metrics.json&#39;</code></pre></div>\n<ol start=\"2\" class=\"pf-c-list\">\n<li>Initialize variables which capture metrics such as time taken to execute certain parts of the code. In the following lines of code, we capture the time taken to upload <code class=\"language-text\">emissions_table1.parquet</code> onto S3 as <code class=\"language-text\">upload_df1_time</code>.</li>\n</ol>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">df_emissions.to_parquet(&quot;/tmp/emissions_table1.parquet&quot;, index=False)\nt = time.time()\ns3.upload_file(\n    Bucket=os.environ[&quot;S3_BUCKET&quot;],\n    Key=&quot;urgentem/trino/itr_emissions_join_1/emissions.parquet&quot;,\n    Filename=&quot;/tmp/emissions_table1.parquet&quot;,\n)\nupload_df1_time = time.time() - t</code></pre></div>\n<ol start=\"3\" class=\"pf-c-list\">\n<li>Aggregate all the metrics captured within the notebook into a dictionary called <code class=\"language-text\">metrics</code> and export the json-serialized metrics dictionary into the <code class=\"language-text\">mlpipeline-metrics</code> file.</li>\n</ol>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">metrics = {\n    &quot;metrics&quot;:[\n        {\n            &quot;name&quot;:&quot;no_rows_emissions_table_1&quot;,\n            &quot;numberValue&quot;:len_emssions_data_1,\n            &quot;format&quot;:&quot;RAW&quot;\n        },\n        {\n            &quot;name&quot;:&quot;no_rows_emissions_table_2&quot;,\n            &quot;numberValue&quot;:len_emssions_data_2,\n            &quot;format&quot;:&quot;RAW&quot;\n        },\n        {\n            &quot;name&quot;:&quot;time_to_upload_df_1&quot;,\n            &quot;numberValue&quot;:upload_df1_time,\n            &quot;format&quot;:&quot;RAW&quot;\n        }\n    ]\n}</code></pre></div>\n<ol start=\"4\" class=\"pf-c-list\">\n<li>Once the notebook is  configured to track metrics and the pipeline has been submitted, you can move over to the kubeflow UI to view the metrics that are being captured during notebook run.</li>\n</ol>\n<p><img src=\"/public/assets/track-metrics-using-kubeflow/metrics.png\" alt=\"metrics\"></p>\n<p>By clicking on a particular run, and moving over to the <code class=\"language-text\">Run output</code> tab, you can view the metrics captured for each notebook during the particular run.</p>\n<ol start=\"5\" class=\"pf-c-list\">\n<li>To compare runs, from the experiments tab, you can select multiple runs and click on “Compare Runs” on the top right. This will show a table comparing the metrics capture during the selected runs.</li>\n</ol>\n<p>This can be especially helpful while tracking multiple model training runs, and can be used to capture model performance metrics.</p>\n<p><img src=\"/public/assets/track-metrics-using-kubeflow/compare-runs.png\" alt=\"metrics\"></p>\n<p>If you want to see an real example of how to integrate experiement tracking, take a look at this <a href=\"https://github.com/os-climate/aicoe-osc-demo/blob/master/notebooks/demo1/demo1-create-tables.ipynb\">notebook</a>.</p>","fields":{"srcLink":"https://github.com/aicoe-aiops/data-science-workflows/blob/master/docs/develop_collaborate/track-metrics-using-kubeflow.md"},"frontmatter":{"title":"","description":null,"extraClasses":null,"banner":null}}},"pageContext":{"id":"102932e4-7a86-5c1a-be9c-6c0815745fcd"}},"staticQueryHashes":["1764348645","2823140819","3000541721","3606484676"]}