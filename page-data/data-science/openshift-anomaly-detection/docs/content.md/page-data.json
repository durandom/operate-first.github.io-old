{"componentChunkName":"component---src-templates-markdown-remark-js","path":"/data-science/openshift-anomaly-detection/docs/content.md","result":{"data":{"site":{"siteMetadata":{"title":"Operate First"}},"markdownRemark":{"id":"f21fc299-14d5-5456-9cfc-d82e9269942f","html":"<h1 id=\"table-of-contents\" style=\"position:relative;\"><a href=\"#table-of-contents\" aria-label=\"table of contents permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Table of Contents</h1>\n<p>This project consists of the following main workstreams:</p>\n<ul class=\"pf-c-list\">\n<li><a href=\"#anomaly-detection\">Anomaly Detection</a></li>\n<li><a href=\"#diagnosis-discovery\">Diagnosis Discovery</a></li>\n</ul>\n<h2 id=\"anomaly-detection\" style=\"position:relative;\"><a href=\"#anomaly-detection\" aria-label=\"anomaly detection permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Anomaly Detection</h2>\n<p>In this approach, we try to identify issues before they occur, or before they significantly impact customers. To do so, we find OpenShift deployments that behave “unusually” or “anomalously” as compared to the rest of the fleet. Then, we try to explain this behavior using some heuristics in a way that is actionable for engineers. The outcome of this approach is that each deployment is given an anomaly score, and the explanation for this score is displayed on a Superset dashboard.</p>\n<ul class=\"pf-c-list\">\n<li><a href=\"../notebooks/stage/anomaly-detection-demo.ipynb\">Notebook</a></li>\n</ul>\n<h2 id=\"diagnosis-discovery\" style=\"position:relative;\"><a href=\"#diagnosis-discovery\" aria-label=\"diagnosis discovery permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Diagnosis Discovery</h2>\n<p>In this approach, we first try to determine which deployments exhibit similar types of “symptoms” (i.e. health problems). Once we have this grouping, we try to figure out the precise set of symptoms that best characterizes the underlying issue in each of the groups of deployments. Support engineers can then use these symptom patterns to determine the “diagnosis” for these problematic deployments, and programatically define the issue.</p>\n<ul class=\"pf-c-list\">\n<li><a href=\"../notebooks/stage/diagnosis-discovery-demo.ipynb\">Notebook</a></li>\n</ul>","fields":{"srcLink":"https://github.com/aicoe-aiops/openshift-anomaly-detection/blob/master/docs/content.md"},"frontmatter":{"title":"","description":null,"extraClasses":null,"banner":null}}},"pageContext":{"id":"f21fc299-14d5-5456-9cfc-d82e9269942f"}},"staticQueryHashes":["1764348645","2823140819","3000541721","3606484676"]}