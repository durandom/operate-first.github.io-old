{"componentChunkName":"component---src-templates-markdown-remark-js","path":"/community-handbook/elyra/docs/source/model-deployment/flask-application.md","result":{"data":{"site":{"siteMetadata":{"title":"Operate First"}},"markdownRemark":{"id":"b08bbbdd-942f-54fc-a683-6be27bf4364c","html":"<h1 id=\"deploy-your-model-as-a-flask-application\" style=\"position:relative;\"><a href=\"#deploy-your-model-as-a-flask-application\" aria-label=\"deploy your model as a flask application permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Deploy your model as a Flask application</h1>\n<h2 id=\"create-your-flask-app\" style=\"position:relative;\"><a href=\"#create-your-flask-app\" aria-label=\"create your flask app permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Create your Flask app</h2>\n<p>Once you’ve trained your model and it’s stored on Ceph, you can start to work on an inference application to make your model accessible. In this tutorial, we will make a minimal <a href=\"https://flask.palletsprojects.com/en/2.0.x/\">Flask</a> + <a href=\"https://docs.gunicorn.org/en/stable/index.html\">gunicorn</a> that we can deploy on OpenShift to serve model inferences. We will also use <a href=\"https://argoproj.github.io/argo-cd/\">ArgoCD</a> for continuous deployment of our application as we make changes.</p>\n<p>For the purpose of the tutorial you can reuse this <a href=\"../../../wsgi.py\">application script</a> created with Flask+gunicorn. This app exposes critical endpoints for serving and monitoring our model, such as <code class=\"language-text\">/predict</code> for generating model predictions from user provided inputs and <code class=\"language-text\">/metrics</code> to measure usage and model performance.</p>\n<h3 id=\"1-make-a-new-release\" style=\"position:relative;\"><a href=\"#1-make-a-new-release\" aria-label=\"1 make a new release permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>1. Make a new release</h3>\n<p>When you make any changes to your model, typically through retraining, and add a new one to Ceph, you will need to <a href=\"../thoth-aicoe-services.md\">create a new release and build the image</a> again. This is because you have made new changes to the model that are not reflected in the current image. Once the new tag is created, the pipeline will automatically update the tag where ArgoCD is looking for changes, and your new image will be rebuilt to include your new model and will be seamlessly redeployed.</p>\n<h3 id=\"2-deploy-your-application\" style=\"position:relative;\"><a href=\"#2-deploy-your-application\" aria-label=\"2 deploy your application permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2. Deploy your application</h3>\n<h4 id=\"requirements-for-tensorflowflaskgunicorn\" style=\"position:relative;\"><a href=\"#requirements-for-tensorflowflaskgunicorn\" aria-label=\"requirements for tensorflowflaskgunicorn permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a><strong>Requirements for Tensorflow+Flask+Gunicorn</strong></h4>\n<ul class=\"pf-c-list\">\n<li>Image Name: <code class=\"language-text\">quay.io/thoth-station/elyra-aidevsecops-tutorial:v0.5.0</code></li>\n<li><a href=\"../../../manifests/overlays/inference/deploymentconfig.yaml\">DeploymentConfig</a>: Deployment configs are templates for running applications on OpenShift. This will give the cluster the necessary information to deploy your Flask application.</li>\n<li><a href=\"../../../manifests/base/service.yaml\">Service</a>: A service manifest allows for an application running on a set of OpenShift pods to be exposed as a network service.</li>\n<li><a href=\"../../../manifests/base/route.yaml\">Route</a>: Routes are used to expose services. This route will give your model deployment a reachable hostname to interact with.</li>\n</ul>\n<h4 id=\"requirements-for-pytorchflaskgunicorn\" style=\"position:relative;\"><a href=\"#requirements-for-pytorchflaskgunicorn\" aria-label=\"requirements for pytorchflaskgunicorn permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a><strong>Requirements for Pytorch+Flask+Gunicorn</strong></h4>\n<ul class=\"pf-c-list\">\n<li>Image Name: <code class=\"language-text\">quay.io/thoth-station/elyra-aidevsecops-pytorch-inference:v0.13.0</code></li>\n<li><a href=\"../../../manifests/overlays/pytorch-inference/deploymentconfig.yaml\">DeploymentConfig</a>: Deployment configs are templates for running applications on OpenShift. This will give the cluster the necessary information to deploy your Flask application.</li>\n<li><a href=\"../../../manifests/overlays/pytorch-inference/service.yaml\">Service</a>: A service manifest allows for an application running on a set of OpenShift pods to be exposed as a network service.</li>\n<li><a href=\"../../../manifests/overlays/pytorch-inference/route.yaml\">Route</a>: Routes are used to expose services. This route will give your model deployment a reachable hostname to interact with.</li>\n</ul>\n<h4 id=\"requirements-for-neuralmagicflaskgunicorn\" style=\"position:relative;\"><a href=\"#requirements-for-neuralmagicflaskgunicorn\" aria-label=\"requirements for neuralmagicflaskgunicorn permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a><strong>Requirements for NeuralMagic+Flask+Gunicorn</strong></h4>\n<p>NOTE: <em>Deepsparse deployment at the moment works only with CPU that supports avx2, avx512 flags (even better if [avx512</em>vnni](<a href=\"https://en.wikichip.org/wiki/x86/avx512_vnni\">https://en.wikichip.org/wiki/x86/avx512_vnni</a>) with VNNI is available: <a href=\"https://github.com/neuralmagic/deepsparse/issues/186\">https://github.com/neuralmagic/deepsparse/issues/186</a>). Please check your environment running <code class=\"language-text\">cat /proc/cpuinfo</code> to identify flags and verify if your machine supports the deployment. In the deployment manifests in <code class=\"language-text\">nm-inference</code> overlay you need to set the env variable NM<em>ARCH=avx2|avx512.</em></p>\n<p>NOTE: Operate First has a <a href=\"http://grafana.operate-first.cloud/d/LCLH8kd7z/node-feature-discovery?orgId=1\">Grafana dashboard</a> showing what hardware and flags are available across all managed instances. In this way, we can identify the best place to deploy the model.</p>\n<ul class=\"pf-c-list\">\n<li>Image Name: <code class=\"language-text\">quay.io/thoth-station/neural-magic-deepsparse:v0.13.0</code></li>\n<li><a href=\"../../../manifests/overlays/nm-inference/deploymentconfig.yaml\">DeploymentConfig</a>: Deployment configs are templates for running applications on OpenShift. This will give the cluster the necessary information to deploy your Flask application.</li>\n<li><a href=\"../../../manifests/overlays/nm-inference/service.yaml\">Service</a>: A service manifest allows for an application running on a set of OpenShift pods to be exposed as a network service.</li>\n<li><a href=\"../../../manifests/overlays/nm-inference/route.yaml\">Route</a>: Routes are used to expose services. This route will give your model deployment a reachable hostname to interact with.</li>\n</ul>\n<h4 id=\"using-operate-first-with-argocd\" style=\"position:relative;\"><a href=\"#using-operate-first-with-argocd\" aria-label=\"using operate first with argocd permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a><strong>Using Operate First with ArgoCD</strong></h4>\n<p>Once all manifests for your project (e.g. deployment, service, routes, workflows, pipelines) are created and placed in your repo under <code class=\"language-text\">/manifests</code> folder, you can make a request to the Operate First team to use ArgoCD for your application.</p>\n<p>This way <a href=\"https://argoproj.github.io/argo-cd/\">ArgoCD</a> will be used to maintain your application and keep it in sync with all of your current changes. Once you create a new release of your application (e.g. you change your model, you add a new metric, you add a new feature, etc.) and a new image is available, all you need to do is update the <a href=\"../../../manifests/overlays/inference/imagestreamtag.yaml#L10\">imagestreamtag</a> so that ArgoCD can deploy new version.</p>\n<p>Note: An <a href=\"https://github.com/AICoE/aicoe-ci\">AICoE Pipeline</a> can also automatically update the <a href=\"../../../manifests/overlays/test/imagestreamtag.yaml#L10\">imagestreamtag</a> once a new release is created.</p>\n<p>Once everything is synced to the cluster, you can monitor your application from the <a href=\"https://argoproj.github.io/argo-cd/\">ArgoCD</a> UI using this <a href=\"https://argocd.operate-first.cloud/applications\">link</a> as shown in the image below:</p>\n<div style=\"text-align:center\">\n<img alt=\"Argo CD UI\" src=\"https://raw.githubusercontent.com/thoth-station/elyra-aidevsecops-tutorial/master/docs/images/ArgoCDUI.png\">\n</div>\n<h5 id=\"during-an-operate-first-based-workshop\" style=\"position:relative;\"><a href=\"#during-an-operate-first-based-workshop\" aria-label=\"during an operate first based workshop permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a><strong>During an Operate First based workshop</strong></h5>\n<p>There are two steps you need to follow in order to have a new application deployed on <a href=\"https://www.operate-first.cloud/\">Operate First</a> and maintained by ArgoCD.</p>\n<ol class=\"pf-c-list\">\n<li>Fork <a href=\"https://github.com/operate-first/workshop-apps\">workshop-apps</a> and clone it from the terminal of your image.</li>\n<li>Run ./devconf-us-2021.sh script with your GitHub username as parameter:</li>\n</ol>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">$ ./devconf-us-2021.sh USERNAME\nGenerating &#39;apps/devconf-us-2021/USERNAME.yaml&#39;</code></pre></div>\n<ol start=\"3\" class=\"pf-c-list\">\n<li>Commit, push to your fork of <a href=\"https://github.com/operate-first/workshop-apps\">workshop-apps</a> and create a PR against orginal repo.</li>\n</ol>\n<h5 id=\"for-application-staying-in-operate-first\" style=\"position:relative;\"><a href=\"#for-application-staying-in-operate-first\" aria-label=\"for application staying in operate first permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a><strong>For application staying in Operate First</strong></h5>\n<p>Submit an issue to <a href=\"https://github.com/operate-first/support/issues/new?assignees=&#x26;labels=onboarding&#x26;template=onboarding_argocd.md&#x26;title=\">operate-first/support</a> to request deployment of your application.</p>\n<h4 id=\"using-openshift-cli\" style=\"position:relative;\"><a href=\"#using-openshift-cli\" aria-label=\"using openshift cli permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a><strong>Using OpenShift CLI</strong></h4>\n<p>Alternatively, you can also deploy your app manually to a cluster using the following OpenShift CLI commands.</p>\n<ol class=\"pf-c-list\">\n<li>Open a terminal in Jupyterlab</li>\n<li>Login from the terminal: <code class=\"language-text\">oc login $CLUSTER_URL</code>.</li>\n<li>Insert your credentials <code class=\"language-text\">USERNAME</code> and <code class=\"language-text\">PASSWORD</code>.</li>\n<li>Make sure you are in <code class=\"language-text\">elyra-aidevsecops-tutorial</code> directory (you can run <code class=\"language-text\">pwd</code> command in the terminal to check your current path).</li>\n<li><code class=\"language-text\">cd</code> to the overlay you want to deploy. (e.g. <code class=\"language-text\">cd manifests/overlays/{inference|pytorch-inference|nm-inference}</code>)</li>\n<li>Create the Service using: <code class=\"language-text\">oc apply -f ./manifests/overlays/{inference|pytorch-inference|nm-inference}/service.yaml</code>.</li>\n<li>Create the Route using: <code class=\"language-text\">oc apply -f ./manifests/overlays/{inference|pytorch-inference|nm-inference}/route.yaml</code>.</li>\n<li>Create the DeploymentConfig using: <code class=\"language-text\">oc apply -f ./manifests/overlays/{inference|pytorch-inference|nm-inference}/deploymentconfig.yaml</code>.</li>\n</ol>\n<p>Once your pods deploy, your Flask app should be ready to serve inference requests from the exposed Route.</p>\n<h2 id=\"next-steps\" style=\"position:relative;\"><a href=\"#next-steps\" aria-label=\"next steps permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Next Steps</h2>\n<p><a href=\"/docs/source/test-model.md\">Test your deployed inference application</a></p>\n<h2 id=\"references\" style=\"position:relative;\"><a href=\"#references\" aria-label=\"references permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>References</h2>\n<ul class=\"pf-c-list\">\n<li><a href=\"https://www.operate-first.cloud/\">Operate First</a></li>\n<li><a href=\"https://argoproj.github.io/argo-cd/\">ArgoCD</a></li>\n<li><a href=\"https://github.com/AICoE/aicoe-ci\">AICoE Pipeline</a></li>\n</ul>","fields":{"srcLink":"https://github.com/thoth-station/elyra-aidevsecops-tutorial/blob/master/docs/source/model-deployment/flask-application.md"},"frontmatter":{"title":"","description":null,"extraClasses":null,"banner":null}}},"pageContext":{"id":"b08bbbdd-942f-54fc-a683-6be27bf4364c"}},"staticQueryHashes":["1764348645","2823140819","3000541721","3606484676"]}